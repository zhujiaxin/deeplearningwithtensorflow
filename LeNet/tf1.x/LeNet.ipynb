{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "import utils.read_mnist as read_mnist\n",
    "import time\n",
    "import lenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把数据读取出来并返回\n",
    "这里提供两个函数\n",
    "分别是read_mnist和read_fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "返回mnist数据，两个参数分别是one_hot和standard来控制是否将数据归一化和变成OneHot\n",
      "        分别返回训练数据，训练标签，测试数据，测试标签\n"
     ]
    }
   ],
   "source": [
    "print(read_mnist.read_mnist.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "返回fashion_mnist数据，两个参数分别是one_hot和standard来控制是否将数据归一化和变成OneHot\n",
      "        分别返回训练数据，训练标签，测试数据，测试标签，按照标签获得名字的一个字典\n"
     ]
    }
   ],
   "source": [
    "print(read_mnist.read_fashion_mnist.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = read_mnist.read_mnist(one_hot=True, standard=True)\n",
    "index_train = np.random.permutation(train_x.shape[0])\n",
    "train_x, train_y = train_x[index_train], train_y[index_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据有60000个,维度为28行，28列\n",
      "测试数据有10000个,维度为28行，28列\n"
     ]
    }
   ],
   "source": [
    "print('训练数据有{}个,维度为{}行，{}列'.format(train_x.shape[0],train_x.shape[1],train_x.shape[2]))\n",
    "print('测试数据有{}个,维度为{}行，{}列'.format(test_x.shape[0],test_x.shape[1],test_x.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "per_process_gpu_memory_fraction: 0.4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_options = tf.GPUOptions(allow_growth=True)     #允许动态申请显存\n",
    "tf.GPUOptions(per_process_gpu_memory_fraction=0.4) # 限制GPU显存使用率是40%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "model = lenet.LeNet(lr_rate=0.001, regular=0.0001)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch use 4556.00 ms\n",
      "0 epoch loss on test data is 2.25 \n",
      "0 epoch accuary on test data is 24.81% \n",
      "1 epoch use 2824.00 ms\n",
      "1 epoch loss on test data is 1.79 \n",
      "1 epoch accuary on test data is 60.10% \n",
      "2 epoch use 2917.00 ms\n",
      "2 epoch loss on test data is 0.69 \n",
      "2 epoch accuary on test data is 82.66% \n",
      "3 epoch use 2934.97 ms\n",
      "3 epoch loss on test data is 0.45 \n",
      "3 epoch accuary on test data is 87.69% \n",
      "4 epoch use 2922.96 ms\n",
      "4 epoch loss on test data is 0.38 \n",
      "4 epoch accuary on test data is 89.45% \n",
      "5 epoch use 2924.96 ms\n",
      "5 epoch loss on test data is 0.34 \n",
      "5 epoch accuary on test data is 90.42% \n",
      "6 epoch use 2932.00 ms\n",
      "6 epoch loss on test data is 0.31 \n",
      "6 epoch accuary on test data is 91.18% \n",
      "7 epoch use 2938.96 ms\n",
      "7 epoch loss on test data is 0.29 \n",
      "7 epoch accuary on test data is 91.87% \n",
      "8 epoch use 2924.00 ms\n",
      "8 epoch loss on test data is 0.27 \n",
      "8 epoch accuary on test data is 92.34% \n",
      "9 epoch use 2921.00 ms\n",
      "9 epoch loss on test data is 0.25 \n",
      "9 epoch accuary on test data is 92.88% \n",
      "10 epoch use 2944.98 ms\n",
      "10 epoch loss on test data is 0.24 \n",
      "10 epoch accuary on test data is 93.46% \n",
      "11 epoch use 3026.96 ms\n",
      "11 epoch loss on test data is 0.22 \n",
      "11 epoch accuary on test data is 93.82% \n",
      "12 epoch use 3001.00 ms\n",
      "12 epoch loss on test data is 0.21 \n",
      "12 epoch accuary on test data is 94.23% \n",
      "13 epoch use 2995.00 ms\n",
      "13 epoch loss on test data is 0.20 \n",
      "13 epoch accuary on test data is 94.51% \n",
      "14 epoch use 2933.00 ms\n",
      "14 epoch loss on test data is 0.19 \n",
      "14 epoch accuary on test data is 94.72% \n",
      "15 epoch use 2933.00 ms\n",
      "15 epoch loss on test data is 0.18 \n",
      "15 epoch accuary on test data is 94.97% \n",
      "16 epoch use 2923.00 ms\n",
      "16 epoch loss on test data is 0.18 \n",
      "16 epoch accuary on test data is 95.15% \n",
      "17 epoch use 2923.00 ms\n",
      "17 epoch loss on test data is 0.17 \n",
      "17 epoch accuary on test data is 95.36% \n",
      "18 epoch use 2922.00 ms\n",
      "18 epoch loss on test data is 0.16 \n",
      "18 epoch accuary on test data is 95.56% \n",
      "19 epoch use 2934.00 ms\n",
      "19 epoch loss on test data is 0.16 \n",
      "19 epoch accuary on test data is 95.85% \n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 64\n",
    "saver = tf.train.Saver()\n",
    "lr_rate = 0.001\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    batch_sofar = 0\n",
    "    for j in range(train_x.shape[0] // batch_size + 1):\n",
    "        model.train(train_x=train_x[batch_sofar:batch_sofar + batch_size, :, :, :],\n",
    "                    train_y=train_y[batch_sofar:batch_sofar + batch_size, :],\n",
    "                    session=sess)\n",
    "        batch_sofar += batch_size\n",
    "        if batch_sofar > train_x.shape[0]:\n",
    "            model.train(train_x=train_x[batch_sofar - batch_size:, :, :, :],\n",
    "                        train_y=train_y[batch_sofar - batch_size:, :],\n",
    "                        session=sess)\n",
    "    if (epoch + 1) / 50 == 0:\n",
    "        lr_rate = lr_rate / 2\n",
    "        model.change_lr_rate(lr_rate)\n",
    "    #rs = sess.run(merge, feed_dict={model.input_x: test_x, model.input_y: test_y})\n",
    "    #file_writer.add_summary(rs, epoch)\n",
    "    print('{:.0f} epoch use {:.2f} ms'.format(epoch, (time.time()-start)*1000))\n",
    "    print('{:.0f} epoch loss on test data is {:.2f} '.format(epoch, model.compute_loss(test_x, test_y, session=sess)))\n",
    "    print('{:.0f} epoch accuary on test data is {:.2f}% '.format(epoch, model.compute_accuracy(test_x, test_y, session=sess)*100))\n",
    "saver.save(sess, r'ckpt/lenet-ckpt', global_step=epoch)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow1.12]",
   "language": "python",
   "name": "conda-env-tensorflow1.12-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
